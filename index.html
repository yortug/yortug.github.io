<center>
    <pre>

<b>Troy Engelhardt</b>
tpengelhardt@gmail.com

<hr>
Last modified: 08 June, 2018

<i>This is a small collection of my projects
hope you enjoy and find something useful.</i>

<a href=https://github.com/yortug>GitHub</a>
<a href=https://twitter.com/troyengelhardt>Twitter</a>
<a href=https://www.linkedin.com/in/troyengelhardt/>LinkedIn</a>
<a href=https://www.facebook.com/troy.engelhardtt>Facebook</a>

<hr>


<h1>and in no particular order</h1>

<a href="optimal_portfolio/optimal_portfolio.html">Optimal Portfolio S&P 500</a>
- latest project completed for university (STAT2005)
- finding the optimal set of stocks to include in a portfolio
- only using companies listed on S&P 500
- finding the optimal weights to distribute $10 million across all stocks

<a href="predicting_aromaticity/predicting_aromaticity.html">Predicting Aromaticity In Diesel Fuels</a>
- my favourite project to work on to date
- predicting the amount of aromaticity (an 'impurity') in diesel fuels using spectroscopy data
- the report goes rather in-depth but I try to keep my explainations rather 'open'
- you should be able to read <i>and understand</i> the introduction and conclusion with almost no prior knowledge
- some fancy tag words to get you excited: simple linear regression, multi linear regression, stepwise variable reduction,
- all subset 'brute force', partial least squares, LASSO and there're some nice visualisations in there too

<a href="drug_dosage/drug_dosage.html">Drug Dosage Simulator</a>
- an attempt to find the optimal dosage of two ''''drugs''''
- an aggregation of .sh scripts called through python
- although the ''''drugs'''' may have some legitimacy concerns, the method and discussion is solid

<a href="text_scrape/text_scrape.html">Website Text-Scrape & NLP Wordcloud</a>
- WARNING: contains explicit language, steer clear if this might offend you
- scraping unstructured, untouched text from an infamous image/discussion board
- processing that data into something in which a word frequency can be calculated
- creating a wordcloud visualisation to display the most used words within this sample
- scraping the country tags, time stamps, and then creating a dynamic dashboard for filtering would be a neat next step

<a href="afl_project/afl_project.html">AFL Predictions</a>
- a loose attempt at trying to predict AFL wins and losses
- data wrangling, exploration and cleaning
- Logistic Regression, K-Nearest Neighbours, Decision Trees/Random Forests
- a huge amount of visualisation (histograms, pie charts, stacked bar plots, etc)

<a href="weather_analysis/weather_analysis.html">Perth Weather Analysis</a>
- exploring the suitability of renewable energy and judging climate through sifting Perth Metro weather data
- which will prevail; wind or solar? is there any evidence for us moving towards serious drought?
- I made heavy use of a python package called bokeh, a javascript based dynamic visualisation tool
- data I used is unfortunately not available to download through my scripts (blame BOM), so updating it was a challenge

<a href="course_weighted_calc/courseWeightedAverageCalc1.0.html">Course Weighted Average Calculator</a>
- a very simple script I whipped up to calculate my current course weighted average
- can be significantly improved by putting data into one single 2-dimensional array
- would like to implement this into a pretty website or dashboard with some visualisation

<br>

<hr/>




</pre></center>