<center>
    <pre>
<p style="text-align: center; margin-bottom: 0; padding-bottom: 0; font-size: 14px">
<b>Troy Engelhardt</b>
troy.engelhardt@hotmail.com
<a href=https://github.com/yortug>GitHub</a>  <a href=https://www.linkedin.com/in/troyengelhardt/>LinkedIn</a>  <a href=https://twitter.com/yortug_>Twitter</a>
</p>

<hr>


<div style="text-align: center; margin-top: -4em">
<div style="display: inline-block; text-align: left;">

<h1>Work/Projects:</h1>

<a href="placeholder/placeholder.html" style="font-size: 18px;">CBH Catcher Tool</a>
- video

<a href="placeholder/placeholder.html" style="font-size: 18px;">CBH GraphQL Mockup</a>
- video

<a href="placeholder/placeholder.html" style="font-size: 18px;">CBH Rainfall Chart Generator</a>
- video

<a href="alcoa_industry_project/MATH3004 - Data Fueled Maintenance in Mining [Troy Engelhardt].pdf" style="font-size: 18px;">Alcoa Industry Project</a>
- pdf knitted to html??
- data fueled maintenance in mining

<a href="alcoa_dashboard_mockup/play_video.html" style="font-size: 18px;">Alcoa Mockup Dashboard</a>
- video

<a href="tree_based_outlier_detection/tree_based_outlier_detection.html" style="font-size: 18px;">Tree Based Outlier Detection</a>
- a dive into how tree-based methods for outlier detection work
- mainly concerned with Isolation Forests (IF) and Extended Isolation Forests (EIF)
- use a common dataset (thyroid function) to compare anomaly scoring the two algorithms
    + leveraging sklearn implementation of IF
    + leveraging the author implementation of EIF (and IF)
    + outlier detection accuracy for both methods
    + anomaly scoring regions (ghosting)
    + etc. etc. etc.
- in order to visualise the data PCA was utilised to reduce the dimensionality to 2D
- all plots were designed to be interactive leveraging the Plotly library
- in the future this entire analysis should be completed across a couple other outlier datasets
- presentation can be found <a href="tree_based_outlier_detection_presentation/index.html">here</a>

<a href="data_mining_assignment/data_mining_assignment.html" style="font-size: 18px;">Data Mining Exercise</a>
- given a dataset with a mixture of categorical and numeric variables, with a target class to predict
- have to exercise the data mining skills required to clean and process the data
    + missing data
    + type casting
    + feature scaling
    + feature selections
    + etc. etc. etc.
- after data cleaning & pre-preocessing was completed, numerous classification models were fit
- this was an exercise in truly diving deep into the sklearn framework (previously unexplored)
- many avenues for research and extended reading/experimentation have come out of this exercise

<a href="optimal_portfolio/optimal_portfolio.html" style="font-size: 18px;">Optimal Portfolio S&P 500</a>
- finding the optimal set of stocks to include within an equity portfolio
- restricted to only using companies who're listed on S&P 500
- the project focuses on finding the optimal weights to distribute a hypothetical $10 million across all stocks
- the final portfolio showcases roughly $1 million profit when it was tested over the Jan-2018 to Jul-2018 period
- as we don't have $10 million to spare, (unfortunately) no money was actually thrown down

<a href="predicting_aromaticity/predicting_aromaticity.html" style="font-size: 18px;">Predicting Aromaticity In Diesel Fuels</a>
- predicting the amount of aromaticity (an 'impurity') in diesel fuels using spectroscopy data
- we go through the process of reducing our large feature set using stepwise variable reduction methods
- we then model this relationship starting with simple linear regression, and moving to the multivariate space
- methods of partial least squares and LASSO are also demonstrated
- showcased some basic, static visualisations looking at model assumptions, outliers, leverage, etc.
- you should (hopefully) be able to understand the introduction and conclusion with almost no prior knowledge


<a href="https://github.com/yortug/electoral-campaign" style="font-size: 18px;">Finding an Optimal Campaign Trail</a>
- an assignment used to learn and explore data structures & algorithms
- scraped wikipedia for the coordinates of all Australian voting electorates
- fed these coordinates through GoogleMap's API to find the estimated driving distance & time
- used this data in combination with the 2016 election data to model an optimal campaign route given a set of 'marginal elecorates'
- documentation.pdf file in the repo explains the project in a lot more depth
- implemented a terminal based program which gives you the option to:
    + filter candidates by state, electorate and party
    + search for candidates by name
    + find a set of marginal electorates
    + find an optimal campaign route through marginal electorates

<a href="weather_analysis/weather_analysis.html" style="font-size: 18px;">Perth Weather Analysis</a>
- a basic look at the weather patterns within Perth (using 2016 BOM data)
- heavy use of the python package 'bokeh' to make my visualisations dynamic and interactive
- the project explores the data to provide evidence for the suitability of renewable energy
- looking into questions like; wind or solar? are we in or heading towards a drought?
- unfortunately BOM doesn't have the data available anymore, still should work, just updating it was a challenge

<a href="afl_project/afl_project.html" style="font-size: 18px;">AFL (Australian Football League) Win/Loss Predictions</a>
- a loose attempt at trying to predict AFL wins and losses
- one of my first projects ever attempted, so the data wrangling, exploration and cleaning is rather basic
- somewhat naively apply logistic regression, k-nearest neighbours and decision trees/random forests
- quite a vast emphasis on visualisation (histograms, pie charts, stacked bar plots, etc.)

<a href="drug_dosage/drug_dosage.html" style="font-size: 18px;">Drug Dosage Simulator</a>
- a drug dosage simulation project, one of my first projects within python
- an attempt to find the optimal dosage of two 'drugs'
- really a test in understanding the language; reading & outputting to files, creating shell scripts, etc.
- although the 'drugs' are contrived examples, the absorbtion formula and the working is actually legitimate

<a href="text_scrape/text_scrape.html" style="font-size: 18px;">Website Text-Scrape & NLP Wordcloud</a>
- a project scraping unstructured, untouched text from an infamous image/discussion board
- then processing that data into something in which a word frequency can be calculated
- a wordcloud visualisation was then created to display the most used words within this sample
- very basic, and not too flashy, but it was just a project carried out in the holidays out of boredom


</div>
</div>

<hr>
Last modified: 08 February, 2022

<i>This is a small collection of my work/projects
hope you enjoy and find something useful.</i>



</pre></center>